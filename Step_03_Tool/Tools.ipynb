{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tools\n",
        "Sabsy phely OpenAI-Agents install karen is command sy => **!pip install openai-agents**"
      ],
      "metadata": {
        "id": "qnbb0Fiu2KFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "souTtNkh2Np-",
        "outputId": "4cf83b2f-8934-473b-b37d-6c888a5bc49a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.2.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.11.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.11.0 (from openai-agents)\n",
            "  Downloading mcp-1.12.4-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m733.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<2,>=1.97.1 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.99.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.14.1)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.97.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.97.1->openai-agents) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.97.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.97.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.26.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.2.5-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.11.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.12.4-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, python-dotenv, httpx-sse, colorama, sse-starlette, griffe, pydantic-settings, mcp, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.11.0 httpx-sse-0.4.1 mcp-1.12.4 openai-agents-0.2.5 pydantic-settings-2.10.1 python-dotenv-1.1.1 sse-starlette-3.0.2 types-requests-2.32.4.20250809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab ky andar Agent ko Asynchronous mein chalanay ky leye **nest_asyncio** ki library install karna paryge"
      ],
      "metadata": {
        "id": "dRokHEIOrjfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hcw5IbKJrg7r",
        "outputId": "20205912-7a75-4c64-a2f8-c58f14ff6b60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create the Simple agent**"
      ],
      "metadata": {
        "id": "pj4A67m02cwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"How are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "-AOkPQZL5WSg",
        "outputId": "126f2fb1-60e5-4880-fb14-f7ab04fa39a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am doing well, thank you for asking! How are you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔸Pyhton Function Tool Agent**"
      ],
      "metadata": {
        "id": "e3S-oqjXs8lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather]\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"what is the weather in karachi\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "        print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKGAaW52tICl",
        "outputId": "67c44fc7-737b-4867-93d1-bbdba492c0fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in karachi is cloudy.\n",
            "\n",
            "fetch_weather\n",
            "This is fetch weather tool\n",
            "{\n",
            "    \"properties\": {\n",
            "        \"city\": {\n",
            "            \"title\": \"City\",\n",
            "            \"type\": \"string\"\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"city\"\n",
            "    ],\n",
            "    \"title\": \"fetch_weather_args\",\n",
            "    \"type\": \"object\",\n",
            "    \"additionalProperties\": false\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔸Custom Function Tool**\n",
        "---\n",
        "Kabhi Kabhi hame python function tool nh chahiye hota tw hum apna khud ka\n",
        "custom tool bhi bana sakty hain **FunctionTool** ka use karky\n",
        "\n",
        "---\n",
        "Typing install karenge taky TypeDict install karky type specify kar saken\n",
        "\n"
      ],
      "metadata": {
        "id": "NfNo92PAw2tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing_extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIIWRUsO50tx",
        "outputId": "2280e3f3-943f-43d7-9a38-a0015561a419"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, FunctionTool, RunContextWrapper\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "# Result ka format define karte hain: hum words aur letters ki ginti return karenge (dono integers)\n",
        "class WordsAndLettersCounter(TypedDict):\n",
        "  words: int\n",
        "  letters: int\n",
        "\n",
        "# Input ka format define karte hain: sirf ek field \"text\" chahiye humein, jo string hogi\n",
        "class CounterInput(BaseModel):\n",
        "  text: str\n",
        "\n",
        "# Yeh async function hai jo tool ka asli kaam karega\n",
        "async def counter_logic(ctx: RunContextWrapper[str], args: str) -> WordsAndLettersCounter:\n",
        "  # args jo JSON string hai usko CounterInput model ke mutabiq parse aur validate karte hain\n",
        "  parsed = CounterInput.model_validate_json(args) # args ko check karta hai ke sahi format mein hai ya nahi\n",
        "  words = parsed.text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(len(letter) for letter in parsed.text)\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "counter_tool = FunctionTool(\n",
        "    name=\"words_letter_counter\", # tool ka naam.\n",
        "    description=\"This tool counts the number of words and letters in a given text.\", #Tool kya karta hai, LLM ko samjhane ke liye.\n",
        "    params_json_schema=CounterInput.model_json_schema(), # yahan auto create kara hay json schmea manually bhi kar sakty hain.\n",
        "    on_invoke_tool=counter_logic # ye json string mein recieve karta hay ToolContext aur return string mein karta hay.\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  agent = Agent(\n",
        "      name = \"Jarvis\",\n",
        "      instructions = \"You are a helpful assistant. if your asks about words and leters count so call the counter Tool\",\n",
        "      tools=[counter_tool]\n",
        "  )\n",
        "\n",
        "  result = await Runner.run(\n",
        "      starting_agent=agent,\n",
        "      input=\"how many letters and words are in this sentence 'my name is Mesum Ali.'\",\n",
        "      run_config=config\n",
        "  )\n",
        "\n",
        "  print(result.final_output)\n",
        "  for tool in agent.tools:\n",
        "    if tool:\n",
        "      print(tool.name)\n",
        "      print(tool.description)\n",
        "      print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZESvcxXw-Y5",
        "outputId": "34789629-b566-469c-b9f1-7be3b531e8ae"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5 words and 21 letters in the sentence 'my name is Mesum Ali.'.\n",
            "\n",
            "words_letter_counter\n",
            "This tool counts the number of words and letters in a given text.\n",
            "{\n",
            "    \"properties\": {\n",
            "        \"text\": {\n",
            "            \"title\": \"Text\",\n",
            "            \"type\": \"string\"\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"text\"\n",
            "    ],\n",
            "    \"title\": \"CounterInput\",\n",
            "    \"type\": \"object\",\n",
            "    \"additionalProperties\": false\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔸Agents as tools**\n",
        "\n",
        "---\n",
        "sytax thek hay sab ok hay jab ap apni openai key attach karenge run hojayega"
      ],
      "metadata": {
        "id": "pfoDlT2QQvGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "\n",
        "    Urdu_Agent = Agent(\n",
        "        name=\"Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Urdu, no explanations, just translation.\",\n",
        "    )\n",
        "\n",
        "    Roman_Urdu_Agent = Agent(\n",
        "        name=\"Roman_Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Roman Urdu, no explanations, just translation.\",\n",
        "    )\n",
        "\n",
        "    Boss = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=(\n",
        "            \"You are an assistant that translates text. \"\n",
        "            \"If the user wants translation to Urdu, call the 'translate_to_urdu' tool with the user's text. \"\n",
        "            \"If the user wants translation to Roman Urdu, call the 'translate_to_roman_urdu' tool with the user's text. \"\n",
        "            \"Only respond with the output from the tools.\"\n",
        "        ),\n",
        "        tools=[\n",
        "            Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Urdu\"\n",
        "            ),\n",
        "            Roman_Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_roman_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Roman Urdu\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Corrected input examples:\n",
        "    input_text = \"Translate 'Hello, how are you?' to Urdu.\"\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=Boss,\n",
        "        input=input_text,\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwpGnhWXQyDO",
        "outputId": "047bbc95-e874-4e88-99ec-9698a17cd403"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am sorry, I cannot fulfill this request. The tool is not working properly. Please try again later.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}