{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI Agents Tools**"
      ],
      "metadata": {
        "id": "GqanKzXAa7qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# OpenAI Agents Setup in Google Colab**\n",
        "\n",
        "Sab se pehle OpenAI Agents aur async code ke liye zaroori libraries install karen:\n",
        "\n",
        "```python\n",
        "!pip install openai-agents\n",
        "!pip install nest_asyncio\n",
        "!pip install typing_extensions  # Custom function tools ke liye\n",
        "```"
      ],
      "metadata": {
        "id": "qnbb0Fiu2KFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "souTtNkh2Np-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab ky andar Agent ko Asynchronous mein chalanay ky leye **nest_asyncio** ki library install karna paryge"
      ],
      "metadata": {
        "id": "dRokHEIOrjfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hcw5IbKJrg7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Simple Async Agent Banana**"
      ],
      "metadata": {
        "id": "pj4A67m02cwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"How are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "-AOkPQZL5WSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Pyhton Function Tool Agent**"
      ],
      "metadata": {
        "id": "e3S-oqjXs8lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather]\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"what is the weather in karachi\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "        print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "iKGAaW52tICl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Custom Function Tool with TypedDict and Pydantic**\n",
        "---\n",
        "Kabhi Kabhi hame python function tool nh chahiye hota tw hum apna khud ka\n",
        "custom tool bhi bana sakty hain **FunctionTool** ka use karky"
      ],
      "metadata": {
        "id": "NfNo92PAw2tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing_extensions"
      ],
      "metadata": {
        "id": "aIIWRUsO50tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, FunctionTool, RunContextWrapper\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "# Result ka format define karte hain: hum words aur letters ki ginti return karenge (dono integers)\n",
        "class WordsAndLettersCounter(TypedDict):\n",
        "  words: int\n",
        "  letters: int\n",
        "\n",
        "# Input ka format define karte hain: sirf ek field \"text\" chahiye humein, jo string hogi\n",
        "class CounterInput(BaseModel):\n",
        "  text: str\n",
        "\n",
        "# Yeh async function hai jo tool ka asli kaam karega\n",
        "async def counter_logic(ctx: RunContextWrapper[str], args: str) -> WordsAndLettersCounter:\n",
        "  # args jo JSON string hai usko CounterInput model ke mutabiq parse aur validate karte hain\n",
        "  parsed = CounterInput.model_validate_json(args) # args ko check karta hai ke sahi format mein hai ya nahi\n",
        "  words = parsed.text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(len(letter) for letter in parsed.text)\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "counter_tool = FunctionTool(\n",
        "    name=\"words_letter_counter\", # tool ka naam.\n",
        "    description=\"This tool counts the number of words and letters in a given text.\", #Tool kya karta hai, LLM ko samjhane ke liye.\n",
        "    params_json_schema=CounterInput.model_json_schema(), # yahan auto create kara hay json schmea manually bhi kar sakty hain.\n",
        "    on_invoke_tool=counter_logic # ye json string mein recieve karta hay ToolContext aur return string mein karta hay.\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  agent = Agent(\n",
        "      name = \"Jarvis\",\n",
        "      instructions = \"You are a helpful assistant. if your asks about words and leters count so call the counter Tool\",\n",
        "      tools=[counter_tool]\n",
        "  )\n",
        "\n",
        "  result = await Runner.run(\n",
        "      starting_agent=agent,\n",
        "      input=\"how many letters and words are in this sentence 'my name is Mesum Ali.'\",\n",
        "      run_config=config\n",
        "  )\n",
        "\n",
        "  print(result.final_output)\n",
        "  for tool in agent.tools:\n",
        "    if tool:\n",
        "      print(tool.name)\n",
        "      print(tool.description)\n",
        "      print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "YZESvcxXw-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Agents as tools**\n",
        "\n",
        "---\n",
        "sytax thek hay sab ok hay jab ap apni openai key attach karenge run hojayega"
      ],
      "metadata": {
        "id": "pfoDlT2QQvGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "\n",
        "    Urdu_Agent = Agent(\n",
        "        name=\"Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Urdu, no explanations, just translation.\",\n",
        "    )\n",
        "\n",
        "    Roman_Urdu_Agent = Agent(\n",
        "        name=\"Roman_Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Roman Urdu, no explanations, just translation.\",\n",
        "    )\n",
        "\n",
        "    Boss = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=(\n",
        "            \"You are an assistant that translates text. \"\n",
        "            \"If the user wants translation to Urdu, call the 'translate_to_urdu' tool with the user's text. \"\n",
        "            \"If the user wants translation to Roman Urdu, call the 'translate_to_roman_urdu' tool with the user's text. \"\n",
        "            \"Only respond with the output from the tools.\"\n",
        "        ),\n",
        "        tools=[\n",
        "            Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Urdu\"\n",
        "            ),\n",
        "            Roman_Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_roman_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Roman Urdu\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Corrected input examples:\n",
        "    input_text = \"Translate 'Hello, how are you?' to Urdu.\"\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=Boss,\n",
        "        input=input_text,\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "id": "KwpGnhWXQyDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Custom output extraction**"
      ],
      "metadata": {
        "id": "ZmkQlSAwbpoy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBTLZfnvb3zP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}